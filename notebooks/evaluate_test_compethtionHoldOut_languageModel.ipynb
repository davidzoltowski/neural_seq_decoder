{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826263a8-5516-4232-8197-5b8dbcd48d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from neural_decoder.neural_decoder_trainer_mamba import loadModel, getDatasetLoaders\n",
    "from neural_decoder.model import GRUDecoder, MambaDecoder\n",
    "from neural_decoder.dataset import SpeechDataset\n",
    "import neuralDecoder.utils.lmDecoderUtils as lmDecoderUtils\n",
    "\n",
    "from edit_distance import SequenceMatcher\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902ad43b-24cd-4f99-bc2a-a2d8ae303e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba_outputs = pickle.load(open('235_mamba_outputs_competition.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c060a14-31a4-45b1-9534-d2c739e50290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44aa2eec936d4c49af839c84b2b79fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "llm, llm_tokenizer = lmDecoderUtils.build_opt(\n",
    "    cacheDir='/scratch/users/hdlee/speech_bci/language_models/llms', device=\"auto\", load_in_8bit=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7afc226c-c8ad-4021-b09a-5b855c50169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I0425 13:04:54.852828 76490 brain_speech_decoder.h:52] Reading fst /scratch/users/hdlee/speech_bci/language_models/speech_5gram/lang_test/TLG.fst\n",
      "I0425 13:09:18.055339 76490 brain_speech_decoder.h:58] Reading lm fst /scratch/users/hdlee/speech_bci/language_models/speech_5gram/lang_test/G.fst\n",
      "I0425 13:10:12.606490 76490 brain_speech_decoder.h:70] Reading rescore fst /scratch/users/hdlee/speech_bci/language_models/speech_5gram/lang_test/G_no_prune.fst\n",
      "I0425 13:24:23.419416 76490 brain_speech_decoder.h:81] Reading symbol table /scratch/users/hdlee/speech_bci/language_models/speech_5gram/lang_test/words.txt\n"
     ]
    }
   ],
   "source": [
    "#loads the language model, could take a while and requires ~60 GB of memory\n",
    "lmDir = '/scratch/users/hdlee/speech_bci/language_models/speech_5gram/lang_test' \n",
    "# lmDir = '/scratch/users/hdlee/speech_bci/language_models/languageModel'\n",
    "ngramDecoder = lmDecoderUtils.build_lm_decoder(\n",
    "    lmDir,\n",
    "    acoustic_scale=0.5,\n",
    "    nbest=100,\n",
    "    beam=18\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e08379-86fe-4851-a95b-dc9d705538f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LM decoding hyperparameters\n",
    "# acoustic_scale = 0.5\n",
    "# blank_penalty = np.log(2)\n",
    "# llm_weight = 0.5\n",
    "\n",
    "# llm_outputs = []\n",
    "# # Generate nbest outputs from an LM\n",
    "# start_t = time.time()\n",
    "# nbest_outputs = []\n",
    "\n",
    "# j = 0\n",
    "# logits = mamba_outputs[\"logits\"][j]\n",
    "# logits = np.concatenate(\n",
    "#     [logits[:, 1:], logits[:, 0:1]], axis=-1\n",
    "# )  # Blank is last token\n",
    "# # print(logits.shape)\n",
    "\n",
    "# logits = lmDecoderUtils.rearrange_speech_logits(logits[None, :, :], has_sil=True)\n",
    "# print(logits.shape)\n",
    "\n",
    "# logPriors = np.zeros([1, logits[0].shape[1]])\n",
    "\n",
    "# import lm_decoder\n",
    "\n",
    "# lm_decoder.DecodeNumpy(ngramDecoder, logits[0], logPriors, blank_penalty)\n",
    "\n",
    "# ngramDecoder.FinishDecoding()\n",
    "\n",
    "# # ngramDecoder.Rescore() #ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a10cb2-74cb-431f-ab68-dee67cd69cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ea17c-5cf7-40ac-9f59-d8b4656b8c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 805/1200 [09:24<03:08,  2.10it/s]"
     ]
    }
   ],
   "source": [
    "# LM decoding hyperparameters\n",
    "acoustic_scale = 0.5\n",
    "blank_penalty = np.log(7)\n",
    "llm_weight = 0.5\n",
    "\n",
    "llm_outputs = []\n",
    "# Generate nbest outputs from an LM\n",
    "start_t = time.time()\n",
    "nbest_outputs = []\n",
    "for j in tqdm(range(len(mamba_outputs[\"logits\"]))):\n",
    "    logits = mamba_outputs[\"logits\"][j]\n",
    "    logits = np.concatenate(\n",
    "        [logits[:, 1:], logits[:, 0:1]], axis=-1\n",
    "    )  # Blank is last token\n",
    "    logits = lmDecoderUtils.rearrange_speech_logits(logits[None, :, :], has_sil=True)\n",
    "    nbest = lmDecoderUtils.lm_decode(\n",
    "        ngramDecoder,\n",
    "        logits[0],\n",
    "        blankPenalty=blank_penalty,\n",
    "        returnNBest=True,\n",
    "        rescore=False,#True,\n",
    "    )\n",
    "    nbest_outputs.append(nbest)\n",
    "time_per_sample = (time.time() - start_t) / len(mamba_outputs[\"logits\"])\n",
    "print(f\"decoding took {time_per_sample} seconds per sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fffe1d-65f4-441b-9a7c-8245455a2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mamba_outputs[\"transcriptions\"])):\n",
    "    new_trans = [ord(c) for c in mamba_outputs[\"transcriptions\"][i]] + [0]\n",
    "    mamba_outputs[\"transcriptions\"][i] = np.array(new_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abc67791-7293-4979-959b-84f2742a909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 5\n",
    "# topk_best_outputs = [output[:k] for output in nbest_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6913c9ef-8ae6-48af-8391-af39d21a8712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974f146ad1fe404fa0d973a8591d1b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Rescore nbest outputs with LLM\n",
    "# start_t = time.time()\n",
    "# llm_out = lmDecoderUtils.cer_with_gpt2_decoder(\n",
    "#     llm,\n",
    "#     llm_tokenizer,\n",
    "#     topk_best_outputs[:],\n",
    "#     acoustic_scale,\n",
    "#     mamba_outputs,\n",
    "#     outputType=\"speech_sil\",\n",
    "#     returnCI=True,\n",
    "#     lengthPenalty=0,\n",
    "#     alpha=llm_weight,\n",
    "# )\n",
    "# time_per_sample = (time.time() - start_t) / len(logits)\n",
    "# print(f\"LLM decoding took {time_per_sample} seconds per sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c76285-f955-4d08-aeb5-85b54bc57da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((nbest_outputs, mamba_outputs), open('./235_inputs_for_decoder_5gram.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3c159-2fc7-46d7-89b9-066c5ecf8da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9959a4-8f06-4e2c-8c0a-24fd7fc3cff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be031f-e26d-4ce5-aa4f-8264ff848b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d87c24-25d6-47dc-8d06-4e83229eaa23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985006239c374dd4a6179919603ecdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "llm, llm_tokenizer = lmDecoderUtils.build_opt(\n",
    "    cacheDir='/scratch/users/hdlee/speech_bci/language_models/llms', device=\"auto\", load_in_8bit=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d872a96-8eb8-4b7b-88fc-af2a9939307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LM decoding hyperparameters\n",
    "acoustic_scale = 0.5\n",
    "blank_penalty = np.log(7)\n",
    "llm_weight = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ffeae6e-0497-4a7b-b08a-76e22f9a4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbest_outputs, mamba_outputs = pickle.load(open('./235_inputs_for_decoder.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e4b86bd-4edf-4111-9efd-3ee471f29b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "topk_best_outputs = [output[:k] for output in nbest_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710fe877-66eb-46d7-a8b0-3b9e6558da11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b46743039d4a819ef59b03aabd218d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rescore nbest outputs with LLM\n",
    "start_t = time.time()\n",
    "llm_out = lmDecoderUtils.cer_with_gpt2_decoder(\n",
    "    llm,\n",
    "    llm_tokenizer,\n",
    "    topk_best_outputs[:],\n",
    "    acoustic_scale,\n",
    "    mamba_outputs,\n",
    "    outputType=\"speech_sil\",\n",
    "    returnCI=True,\n",
    "    lengthPenalty=0,\n",
    "    alpha=llm_weight,\n",
    ")\n",
    "# time_per_sample = (time.time() - start_t) / len(logits)\n",
    "# print(f\"LLM decoding took {time_per_sample} seconds per sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a61d61a-df2f-4b98-99a2-7dc93fbbe104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.1315625, 3.069059895833333, 3.195) (3.067083333333333, 3.0091666666666668, 3.1258333333333335)\n"
     ]
    }
   ],
   "source": [
    "print(llm_out[\"cer\"], llm_out[\"wer\"])\n",
    "with open(\"/scratch/users/hdlee/speech_bci/logs/Mamba_Run2_speckled_masking_layerNorm_standardized_bidirectional_6layers/llm_out\", \"wb\") as handle:\n",
    "    pickle.dump(llm_out, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d823fad4-696b-4247-b974-23e4940017a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodedTranscriptions = llm_out[\"decoded_transcripts\"]\n",
    "with open(\"./235_3gramLLMCompetitionSubmission.txt\", \"w\") as f:\n",
    "    for x in range(len(decodedTranscriptions)):\n",
    "        f.write(decodedTranscriptions[x] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fc1022-9f57-4e76-9397-27555602e2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c5b98-a68b-4ddb-aec4-38c87101a473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dab79c-3cda-48b3-b037-52fb9413c26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d3968-220c-442d-aa05-8f4fe4afa680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d94bd-e702-46b4-b3d8-5237fe185036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0098b602-332d-46cc-8ae9-22a0f30dc769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc96f7-3730-46d8-893b-63ad84bcf85d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd7516-f4b5-4466-82aa-a5d7589ccd10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f8443-1623-4030-bffe-4d04b6b9821f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc1660-fd5f-4909-a1f0-1d90139aee11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3445a9-1699-4217-8985-b1bdf1b236b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c9ea60-26dc-43fc-8fa5-c0a5183aa3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49adab0f-35f3-4f96-8deb-f9db0df3e967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f01ac-b1dd-431a-8846-3aed71a153c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1eee57-a677-4c35-bb9d-92730c065a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48ace6-470b-4175-a3dc-efa82ff4eb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6529f8-f0d6-45e8-89af-258eb7feb6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf09e910-4647-4069-a432-84fe6836141c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e226af86-da13-44ec-ac6a-db669d30605a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff1f37-d7ef-45fb-926d-130d66c5e964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4fc04-8f3e-45fb-8a58-afe020f16d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d1256f-5426-4884-b99c-5448e042923f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98b742d9-f954-4455-8847-4870c09e578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_transcriptions(inferenceOut):\n",
    "    transcriptions = []\n",
    "    for i in range(len(inferenceOut['transcriptions'])):\n",
    "        endIdx = np.argwhere(inferenceOut['transcriptions'][i] == 0)[0, 0]\n",
    "        trans = ''\n",
    "        for c in range(endIdx):\n",
    "            trans += chr(inferenceOut['transcriptions'][i][c])\n",
    "        transcriptions.append(trans)\n",
    "\n",
    "    return transcriptions\n",
    "\n",
    "trueSentences = _extract_transcriptions(mamba_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e444f6-5f3d-4f51-809b-925f56382acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nbest_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c8b44-a83e-47ee-a280-1d90d4aadb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sentences = []\n",
    "for output in nbest_outputs:\n",
    "    decoded_sentences.append(output[0][0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b700ca5-3ec8-4b4e-96e7-01dda1699d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(decoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42bad3c-751f-40cc-be9f-63b100a80234",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sentences[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94334805-761c-4054-b908-52c7d30715ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testCompetitionSubmission.txt', 'w') as f:\n",
    "    for x in range(len(decoded_sentences)):\n",
    "        f.write(decoded_sentences[x]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f0aa1-2f66-4158-bd78-a887f8a94eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45572035-a46e-4bbe-95ae-f4ea309ad119",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ml load cudnn/8.6.0.163\n",
    "!ml load cuda/11.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30762e6-9fa1-4bd3-8e64-33b59fb92b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "modelName = 'facebook/opt-6.7b'\n",
    "cacheDir = '/scratch/users/hdlee/speech_bci/language_models/llms'\n",
    "device = 'auto'\n",
    "load_in_8bit = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelName, cache_dir=cacheDir)\n",
    "model = AutoModelForCausalLM.from_pretrained(modelName, cache_dir=cacheDir,\n",
    "                                             device_map=device, load_in_8bit=load_in_8bit)\n",
    "\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dec0b9c-0aa0-4ef4-90ff-3f7075873753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescore nbest outputs with LLM\n",
    "start_t = time.time()\n",
    "llm_out = lmDecoderUtils.cer_with_gpt2_decoder(\n",
    "    llm,\n",
    "    llm_tokenizer,\n",
    "    nbest_outputs[:],\n",
    "    acoustic_scale,\n",
    "    mamba_outputs,\n",
    "    outputType=\"speech_sil\",\n",
    "    returnCI=True,\n",
    "    lengthPenalty=0,\n",
    "    alpha=llm_weight,\n",
    ")\n",
    "time_per_sample = (time.time() - start_t) / len(logits)\n",
    "print(f\"LLM decoding took {time_per_sample} seconds per sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d503f4-ed12-456f-89e8-53bd512cbadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm_out[\"cer\"], llm_out[\"wer\"])\n",
    "with open(input_args.modelPath + \"/llm_out\", \"wb\") as handle:\n",
    "    pickle.dump(llm_out, handle)\n",
    "\n",
    "decodedTranscriptions = llm_out[\"decoded_transcripts\"]\n",
    "with open(input_args.modelPath + \"/LLMCompetitionSubmission.txt\", \"w\") as f:\n",
    "    for x in range(len(decodedTranscriptions)):\n",
    "        f.write(decodedTranscriptions[x] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49adb42c-3297-4363-99c0-b9c12e43a102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "bci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
